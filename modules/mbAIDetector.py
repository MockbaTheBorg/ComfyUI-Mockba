"""
AI Image Detection Node for ComfyUI
Detects if an image is AI-generated using open-source machine learning models.
"""

# Standard library imports
import warnings
warnings.filterwarnings("ignore")

# Third-party imports
import numpy as np
import torch
from PIL import Image
from transformers import AutoImageProcessor, AutoModelForImageClassification, BeitImageProcessor, BeitForImageClassification

class mbAIDetector:
    """Detect if an image is AI-generated using pre-trained models."""
    
    # Model constants
    DEFAULT_MODEL = "umm-maybe/AI-image-detector"
    MODELS = [
        "umm-maybe/AI-image-detector",              # General AI image detector
        "Organika/sdxl-detector",                   # SDXL-specific detector
        "TimKond/diffusion-detection",              # Stable Diffusion v1.x detector (trained on Realistic Vision v1.4)
        "dima806/deepfake_vs_real_image_detection", # Deepfake detection (faces)
        "dima806/ai_vs_real_image_detection",       # AI vs Real image detection (CIFAKE dataset)
        "saltanat/anime-ai-detect"                 # Anime AI detector
    ]
    
    # Cache for loaded models
    _model_cache = {}
    
    def __init__(self):
        """Initialize the AI detector node."""
        pass

    @classmethod
    def INPUT_TYPES(cls):
        """Define input types for AI detection."""
        return {
            "required": {
                "image": ("IMAGE", {
                    "tooltip": "Input image to analyze for AI generation"
                }),
                "model": (cls.MODELS, {
                    "default": cls.DEFAULT_MODEL,
                    "tooltip": "Select AI detection model to use"
                }),
                "confidence_threshold": ("FLOAT", {
                    "default": 0.5,
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.01,
                    "tooltip": "Confidence threshold for AI detection (0.0-1.0)"
                })
            },
            "optional": {
                "return_probabilities": ("BOOLEAN", {
                    "default": True,
                    "tooltip": "Return detailed probability scores"
                })
            }
        }

    # Node metadata
    TITLE = "AI Image Detector"
    RETURN_TYPES = ("BOOLEAN", "FLOAT", "FLOAT", "STRING", "STRING")
    RETURN_NAMES = ("is_ai_generated", "ai_probability", "human_probability", "prediction", "model_info")
    FUNCTION = "detect_ai_image"
    CATEGORY = "unset"
    DESCRIPTION = "Detect if an image was generated by AI using machine learning models. Supports multiple detection models including general AI detection, SDXL detection, Stable Diffusion v1.x detection, deepfake detection, AI vs real detection, and anime AI detection."

    def detect_ai_image(self, image, model, confidence_threshold=0.5, return_probabilities=True):
        """
        Analyze image to detect if it's AI-generated.
        
        Args:
            image: Input image tensor
            model: Model name to use for detection
            confidence_threshold: Threshold for AI detection
            return_probabilities: Whether to return detailed probabilities
            
        Returns:
            tuple: (is_ai_generated, ai_probability, human_probability, prediction_text, model_info)
        """
        try:
            # Convert tensor to PIL Image
            pil_image = self._tensor_to_pil(image)
            
            # Load model and processor
            processor, model_obj = self._load_model(model)
            
            # Preprocess image
            inputs = processor(pil_image, return_tensors="pt")
            
            # Run inference
            with torch.no_grad():
                outputs = model_obj(**inputs)
                probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)
                
            # Extract probabilities
            probs = probabilities[0].cpu().numpy()
            
            # Determine labels based on model
            if "anime-ai-detect" in model:
                # This model typically has [human, ai] labels
                human_prob = float(probs[0])
                ai_prob = float(probs[1])
            elif "diffusion-detection" in model:
                # TimKond/diffusion-detection: [real, generated] labels
                # Label 0: real images, Label 1: generated/AI images
                human_prob = float(probs[0])
                ai_prob = float(probs[1])
            elif "dima806/" in model:
                # Both dima806 models: [Real, Fake] or [REAL, FAKE] labels
                # Label 0: Real images, Label 1: Fake/AI images
                human_prob = float(probs[0])
                ai_prob = float(probs[1])
            else:
                # Most models have [ai, human] or similar ordering
                # We'll check the model config for label mapping
                try:
                    id2label = model_obj.config.id2label
                    if "artificial" in str(id2label).lower() or "fake" in str(id2label).lower():
                        ai_prob = float(probs[0])
                        human_prob = float(probs[1])
                    else:
                        # Assume first is human, second is AI
                        human_prob = float(probs[0])
                        ai_prob = float(probs[1])
                except:
                    # Fallback: assume [human, ai] ordering
                    human_prob = float(probs[0])
                    ai_prob = float(probs[1])
            
            # Make prediction
            is_ai_generated = ai_prob > confidence_threshold
            
            # Create prediction text based on model type
            if "deepfake_vs_real_image_detection" in model:
                if is_ai_generated:
                    prediction_text = f"Deepfake Detected (confidence: {ai_prob:.2%})"
                else:
                    prediction_text = f"Real Image (confidence: {human_prob:.2%})"
            elif "ai_vs_real_image_detection" in model:
                if is_ai_generated:
                    prediction_text = f"AI Generated (confidence: {ai_prob:.2%})"
                else:
                    prediction_text = f"Real Image (confidence: {human_prob:.2%})"
            else:
                if is_ai_generated:
                    prediction_text = f"AI Generated (confidence: {ai_prob:.2%})"
                else:
                    prediction_text = f"Human Created (confidence: {human_prob:.2%})"
            
            # Model info
            model_info = f"Model: {model}, Threshold: {confidence_threshold}"
            
            print(f"AI Detection Result: {prediction_text}")
            print(f"AI Probability: {ai_prob:.4f}, Human Probability: {human_prob:.4f}")
            
            return (is_ai_generated, ai_prob, human_prob, prediction_text, model_info)
            
        except Exception as e:
            error_msg = f"AI detection failed: {str(e)}"
            print(error_msg)
            # Return safe defaults on error
            return (False, 0.0, 1.0, f"Error: {error_msg}", f"Model: {model} (failed)")

    def _tensor_to_pil(self, tensor):
        """Convert ComfyUI image tensor to PIL Image."""
        # tensor is typically [batch, height, width, channels]
        if tensor.dim() == 4:
            tensor = tensor[0]  # Take first image from batch
        
        # Convert to numpy and ensure proper range [0, 255]
        if tensor.max() <= 1.0:
            tensor = tensor * 255
        
        array = tensor.cpu().numpy().astype(np.uint8)
        
        # Handle different channel arrangements
        if array.shape[-1] == 3:  # RGB
            pil_image = Image.fromarray(array, 'RGB')
        elif array.shape[-1] == 4:  # RGBA
            pil_image = Image.fromarray(array, 'RGBA')
        else:  # Grayscale
            if len(array.shape) == 3 and array.shape[-1] == 1:
                array = array[:, :, 0]
            pil_image = Image.fromarray(array, 'L').convert('RGB')
        
        return pil_image

    def _load_model(self, model_name):
        """Load and cache the specified model."""
        if model_name in self._model_cache:
            return self._model_cache[model_name]
        
        try:
            print(f"Loading AI detection model: {model_name}")
            
            # Handle different model architectures
            if "diffusion-detection" in model_name:
                # TimKond/diffusion-detection uses BEiT architecture
                processor = BeitImageProcessor.from_pretrained(model_name)
                model = BeitForImageClassification.from_pretrained(model_name)
            else:
                # Standard transformers models
                processor = AutoImageProcessor.from_pretrained(model_name)
                model = AutoModelForImageClassification.from_pretrained(model_name)
            
            # Set to evaluation mode
            model.eval()
            
            # Cache the loaded model
            self._model_cache[model_name] = (processor, model)
            
            print(f"Successfully loaded model: {model_name}")
            return processor, model
            
        except Exception as e:
            error_msg = f"Failed to load model {model_name}: {str(e)}"
            print(error_msg)
            
            # Try to download if not found
            if "not found" in str(e).lower() or "404" in str(e):
                print(f"Model {model_name} not found locally, this may be normal on first use.")
                print("The model will be downloaded automatically from HuggingFace Hub.")
            
            raise Exception(error_msg)

    @classmethod
    def IS_CHANGED(cls, image, model, confidence_threshold, return_probabilities=True):
        """Check if inputs have changed to determine if node needs to re-execute."""
        # Always re-execute when image changes
        return True